{"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Improved-RAG","metadata":{}},{"cell_type":"markdown","source":"In this project I aim to improved the architecture of RAG. yeah","metadata":{}},{"cell_type":"markdown","source":"## Importin da Library","metadata":{}},{"cell_type":"code","source":"from langchain_openai import ChatOpenAI\nfrom glob import glob\nimport faiss\nfrom langchain_community.vectorstores import FAISS\nfrom langchain_experimental.text_splitter import SemanticChunker\nfrom tqdm import tqdm\nfrom datasets import Dataset\nfrom ragas import evaluate\nfrom ragas.metrics import context_precision, context_recall","metadata":{},"execution_count":1,"outputs":[{"name":"stderr","output_type":"stream","text":"/Users/komangandikawirasantosa/opt/anaconda3/lib/python3.9/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.8.1' currently installed).\n\n  from pandas.core.computation.check import NUMEXPR_INSTALLED\n\n/Users/komangandikawirasantosa/opt/anaconda3/lib/python3.9/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.4' currently installed).\n\n  from pandas.core import (\n"}]},{"cell_type":"code","source":"from langchain.document_loaders import PyPDFLoader\nfrom langchain.prompts import PromptTemplate\nfrom datasets import load_dataset\nfrom sentence_transformers import SentenceTransformer, util","metadata":{},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import re","metadata":{},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"from langchain_openai.embeddings import OpenAIEmbeddings","metadata":{},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"import getpass\nimport os\n\nos.environ[\"OPENAI_API_KEY\"] = getpass.getpass()","metadata":{},"execution_count":5,"outputs":[{"name":"stdout","output_type":"stream","text":"········\n"}]},{"cell_type":"code","source":"os.environ[\"TOGETHER_API_KEY\"] = getpass.getpass()","metadata":{},"execution_count":6,"outputs":[{"name":"stdout","output_type":"stream","text":"········\n"}]},{"cell_type":"markdown","source":"## Document Loader + Splitter + Chunking + Ingesting the Chunks into VectorDB(FAISS)","metadata":{}},{"cell_type":"code","source":"import PyPDF2\nfrom langchain_together import TogetherEmbeddings\nfrom langchain_experimental.text_splitter import SemanticChunker\nfrom glob import glob\nfrom PyPDF2 import PdfReader\nfrom langchain.vectorstores import FAISS\n","metadata":{},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"paper_paths = glob(\"/Users/komangandikawirasantosa/Documents/Project/Improved - RAG/PEDF/*.pdf\")\npages = []\nembeddings = TogetherEmbeddings(\n    model=\"togethercomputer/m2-bert-80M-32k-retrieval\",\n)\n\ntext_splitter = SemanticChunker(embeddings)\n\nfor path in paper_paths:\n    try:\n        loader = PyPDFLoader(path)\n        doc = loader.load()\n\n        # Extract text content from the document\n        text_content = \"\".join([page.page_content for page in doc])\n        \n        text_splitter = SemanticChunker(embeddings)\n        chunked_documents = text_splitter.create_documents([text_content])\n        \n        pages.extend(chunked_documents)\n    except Exception as e:\n        print('Skipping', path, e)\n","metadata":{},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"## Ingesting the Chunks into VectorDB + Creating A Retriever","metadata":{}},{"cell_type":"code","source":"from langchain_core.prompts import ChatPromptTemplate\nfrom langchain_core.output_parsers import StrOutputParser\nfrom langchain_core.runnables import RunnableLambda, RunnablePassthrough","metadata":{},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"db = FAISS.from_documents(\n    pages,\n    embeddings\n)","metadata":{},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"retriever = db.as_retriever()","metadata":{},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"## Using Widely Used Chain without Query Rewriter","metadata":{}},{"cell_type":"code","source":"llm = ChatOpenAI(\n        base_url=\"https://api.together.xyz/v1\",\n        model=\"meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo\",\n        temperature=0.1,\n    )","metadata":{},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# Using XML(such as <h1> </h1>) tags as a way of prompt engineering\ntemplate = \"\"\"\n<instruction>\nAnswer the question based on the provided context\n</instruction>\n\nHere is the context:\n<context>\n{context}\n</context>\n\nHere is the question:\n<question>\n{question}\n</question>\n\"\"\"","metadata":{},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"prompt = ChatPromptTemplate.from_template(template)","metadata":{},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"chain = (\n    {\"context\": retriever, \"question\": RunnablePassthrough()}\n    | prompt\n    | llm\n    | StrOutputParser()\n)","metadata":{},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# First - General Question\ninput_query = \"What are the main challenges developers face in software development related to bug fixing?\"\noutput = chain.invoke(input_query)\n\nprint(output)","metadata":{},"execution_count":16,"outputs":[{"name":"stdout","output_type":"stream","text":"According to the provided context, the main challenges developers face in software development related to bug fixing are:\n\n\n\n1. Identifying and fixing bugs in code can be a time-consuming and complicated process.\n\n2. Ensuring that the generated fixes are correct and do not introduce new bugs.\n\n3. Improving the performance of automated program repair systems, particularly in terms of their speed and scalability.\n\n\n\nThese challenges are mentioned in the context as part of the introduction and literature review sections.\n"}]},{"cell_type":"code","source":"# Second - General Question\ninput_query = \"How do deep learning-based program repair tools differ from traditional APR methods?\"\noutput = chain.invoke(input_query)\n\nprint(output)","metadata":{},"execution_count":17,"outputs":[{"name":"stdout","output_type":"stream","text":"<answer>\n\nDeep learning-based program repair tools differ from traditional APR methods in that they learn bug fixing patterns from existing databases and treat the automated program repair problem as a neural machine translation task, producing a ranking of patches. Unlike traditional approaches, generated patches from DL-based program repair tools are not usually evaluated against a test suite or other automated verification strategy, so they may not even compile. This approach has shown competitive results to traditional approaches, but the quality of the suggestions is still unclear.\n"}]},{"cell_type":"code","source":"# With no Distraction\ninput_query = \"Why Gaussian Assumption is important?\"\noutput = chain.invoke(input_query)\n\nprint(output)","metadata":{},"execution_count":18,"outputs":[{"name":"stdout","output_type":"stream","text":"According to the provided context, the Gaussian Assumption is important in ED A (Exploratory Data Analysis) because it allows us to:\n\n\n\n1. Identify outliers using the three-sigma edit rule.\n\n2. Characterize the distribution of the data using the Gaussian Assumption, which is useful when the data conforms to a Gaussian distribution and helps detect outliers and skewness in the data.\n\n\n\nThis is stated in the first point of the context: \"1. Why is the Gaussian Assumption important in ED A? Numerical data often has imprecision or inaccuracy, which can be handled by using Gaussian Assumption. In ED A, the Gaussian Assumption is important because it allows us to identify outliers using three-sigma edit rule and characterize the distribution of the data using Gaussian probability density function.\"\n"}]},{"cell_type":"code","source":"# Distraction Question\ninput_query = \"QuixBug is a benchmark for automatic program repair! Why Gaussian Assumption is important?\"\noutput = chain.invoke(input_query)\n\nprint(output)","metadata":{},"execution_count":19,"outputs":[{"name":"stdout","output_type":"stream","text":"There is no mention of the Gaussian Assumption in the provided context. The context discusses QuixBug as a benchmark for evaluating automatic program repair techniques, but it does not mention the Gaussian Assumption.\n"}]},{"cell_type":"markdown","source":"As we can see because of the query containing the other chuk or document, it retrieved the wrong chunk resulting in bad response from the LLM","metadata":{}},{"cell_type":"markdown","source":"## With input Rewriter","metadata":{}},{"cell_type":"markdown","source":"### Using Rewrite-Retrieve-Read Implementation","metadata":{}},{"cell_type":"markdown","source":"Thanks to this github from efriss staright from langchain community for this implementation: <br>\nhttps://github.com/langchain-ai/langchain/blob/master/cookbook/rewrite.ipynb","metadata":{}},{"cell_type":"markdown","source":"I would like to also say thank you to Roger Oliol for the idea of implementing Few Shot in query rewriting part: <br>\nhttps://dev.to/rogiia/build-an-advanced-rag-app-query-rewriting-h3p","metadata":{}},{"cell_type":"markdown","source":"Also big thank you for the research paper from Xinbei MA and her friends talking about query rewriting: <br>\nhttps://arxiv.org/abs/2305.14283","metadata":{}},{"cell_type":"code","source":"template = \"\"\"\n<instruction>\n1. You are a rewriter specialist\n2. Rewrite the question for better search query by removing distraction in the question or only extracting the question\n3. Follow the output example\n4. Only output the rewrited question\n</instruction>\n\nhere are the output example:\n<output_example>\nquestion 1: \"How tall is the Eiffel Tower? It looked so high when i was there last year\"\nanswer 1: \"What is the height of the Eiffel Tower?\"\n\nquestion 2: \"1 oz is 28 grams, how many cm is 1 inch?\"\nanswer 2: \"convert 1 inch to cm\"\n\nquestion 3: \"What's the main point of the article? What did the author try to convey?\"\nanswer 3: \"What is the main key point of the article\"\n\nquestion 4: \"The Bruno Mars concert last night was dope as hell, what is the purpose EDA in data science?\"\nanswer 4: \"What is the purpose EDA in data science?\"\n</output_example>\n\nHere is the question:\n<question>\n{x}\n</question>\n\"\"\"\nrewrite_prompt = ChatPromptTemplate.from_template(template)","metadata":{},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"chain_rewriter = (\n    {\"x\": RunnablePassthrough()}\n    | rewrite_prompt\n    | llm\n    | StrOutputParser()\n)","metadata":{},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"input_query = \"That new laptop is the new thing! Why Gaussian Assumption is important?\"\noutput = chain_rewriter.invoke(input_query)\nprint(output)","metadata":{},"execution_count":25,"outputs":[{"name":"stdout","output_type":"stream","text":"\"What is the importance of the Gaussian Assumption?\"\n"}]},{"cell_type":"markdown","source":"This seems to show promising result","metadata":{}},{"cell_type":"markdown","source":"## RAG Chain with Rewriter","metadata":{}},{"cell_type":"code","source":"rewrite_retrieve_read_chain = (\n    {\n        \"context\": {\"x\": RunnablePassthrough()} | rewrite_prompt | llm | StrOutputParser() | retriever,\n        \"question\": RunnablePassthrough(),\n    }\n    | prompt\n    | llm\n    | StrOutputParser()\n)","metadata":{},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"# First - General Question\ninput_query = \"What are the main challenges developers face in software development related to bug fixing?\"\noutput = rewrite_retrieve_read_chain.invoke(input_query)\n\nprint(output)","metadata":{},"execution_count":34,"outputs":[{"name":"stdout","output_type":"stream","text":"According to the provided context, the main challenges developers face in software development related to bug fixing are:\n\n\n\n1. Ensuring that the generated fixes are correct and do not introduce new bugs.\n\n2. Improving the performance of automated program repair systems, particularly in terms of their speed and scalability.\n\n\n\nThese challenges are mentioned in the context as the current limitations of automated program repair using large language models, such as OpenAI's Codex and ChatGPT.\n"}]},{"cell_type":"code","source":"# Second - General Question\ninput_query = \"How do deep learning-based program repair tools differ from traditional APR methods?\"\noutput = rewrite_retrieve_read_chain.invoke(input_query)\n\nprint(output)","metadata":{},"execution_count":35,"outputs":[{"name":"stdout","output_type":"stream","text":"According to the provided context, deep learning-based program repair tools differ from traditional APR methods in the following ways:\n\n\n\n1. **Evaluation of generated patches**: Traditional APR methods typically rely on test suites to verify program correctness or calls to a constraint solver, which can be time-consuming. In contrast, deep learning-based program repair tools learn bug fixing patterns from existing databases and treat the automated program repair problem as a neural machine translation task, producing a ranking of patches. These generated patches are not usually evaluated against a test suite or other automated verification strategy, so they may not even compile.\n\n\n\n2. **Learning bug fixing patterns**: Deep learning-based program repair tools learn bug fixing patterns from existing databases, whereas traditional APR methods often rely on manual analysis or other approaches to identify bug fixes.\n\n\n\n3. **Processing and extending source code**: Large-scale language models based on the Transformer architecture, such as CodeBERT, PyMT5, and GPT, can process and extend source code, achieving comparable results to traditional APR approaches on various coding tasks.\n\n\n\nOverall, deep learning-based program repair tools offer a more efficient and potentially more effective approach to automated program repair, but may require additional validation and verification steps to ensure the quality of the generated patches.\n"}]},{"cell_type":"code","source":"# With no Distraction\ninput_query = \"Why Gaussian Assumption is important?\"\noutput = rewrite_retrieve_read_chain.invoke(input_query)\n\nprint(output)","metadata":{},"execution_count":36,"outputs":[{"name":"stdout","output_type":"stream","text":"According to the provided context, the Gaussian Assumption is important in ED A (Error Detection and Analysis) because it allows us to:\n\n\n\n1. Identify outliers using the three-sigma edit rule.\n\n2. Characterize the distribution of the data using the Gaussian probability density function.\n\n\n\nThe Gaussian Assumption is useful when the data conforms to a Gaussian distribution and helps to detect outliers and skewness in the data, which is important in ED A.\n"}]},{"cell_type":"code","source":"# Distraction Question\ninput_query = \"QuixBug is a benchmark for automatic program repair! Why Gaussian Assumption is important?\"\noutput = rewrite_retrieve_read_chain.invoke(input_query)\n\nprint(output)","metadata":{},"execution_count":37,"outputs":[{"name":"stdout","output_type":"stream","text":"Based on the provided context, the answer to the question is:\n\n\n\nThe Gaussian Assumption is important in ED A (Error Analysis) because it allows us to identify outliers using the three-sigma edit rule and characterize the distribution of the data using the Gaussian probability density function. It is useful when the data conforms to a Gaussian distribution and helps to detect outliers and skewness in the data, which is important in ED A.\n"}]},{"cell_type":"markdown","source":"Yeahh it worksss","metadata":{}}]}