{"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30761,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Improved-RAG","metadata":{}},{"cell_type":"markdown","source":"In this project I aim to improved the architecture of RAG. yeah","metadata":{}},{"cell_type":"markdown","source":"## Importin da Library","metadata":{}},{"cell_type":"code","source":"from langchain_openai import ChatOpenAI\nfrom glob import glob\nimport faiss\nfrom langchain_community.vectorstores import FAISS\nfrom langchain_experimental.text_splitter import SemanticChunker\nfrom tqdm import tqdm\nfrom datasets import Dataset\nfrom ragas import evaluate\nfrom ragas.metrics import context_precision, context_recall","metadata":{},"execution_count":1,"outputs":[{"name":"stderr","output_type":"stream","text":"/Users/komangandikawirasantosa/opt/anaconda3/lib/python3.9/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.8.1' currently installed).\n\n  from pandas.core.computation.check import NUMEXPR_INSTALLED\n\n/Users/komangandikawirasantosa/opt/anaconda3/lib/python3.9/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.4' currently installed).\n\n  from pandas.core import (\n"}]},{"cell_type":"code","source":"from langchain.document_loaders import PyPDFLoader\nfrom langchain.prompts import PromptTemplate\nfrom datasets import load_dataset\nfrom sentence_transformers import SentenceTransformer, util","metadata":{},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import re","metadata":{},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"from langchain_openai.embeddings import OpenAIEmbeddings","metadata":{},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"import getpass\nimport os\n\nos.environ[\"OPENAI_API_KEY\"] = getpass.getpass()","metadata":{},"execution_count":5,"outputs":[{"name":"stdout","output_type":"stream","text":"········\n"}]},{"cell_type":"code","source":"os.environ[\"TOGETHER_API_KEY\"] = getpass.getpass()","metadata":{},"execution_count":6,"outputs":[{"name":"stdout","output_type":"stream","text":"········\n"}]},{"cell_type":"code","source":"os.environ[\"CO_API_KEY\"] = getpass.getpass()","metadata":{},"execution_count":32,"outputs":[{"name":"stdout","output_type":"stream","text":"········\n"}]},{"cell_type":"markdown","source":"## Document Loader + Splitter + Chunking + Ingesting the Chunks into VectorDB(FAISS)","metadata":{}},{"cell_type":"code","source":"import PyPDF2\nfrom langchain_together import TogetherEmbeddings\nfrom langchain_experimental.text_splitter import SemanticChunker\nfrom glob import glob\nfrom PyPDF2 import PdfReader\nfrom langchain.vectorstores import FAISS\n","metadata":{},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"paper_paths = glob(\"/Users/komangandikawirasantosa/Documents/Project/Improved - RAG/PEDF/*.pdf\")\npages = []\nembeddings = TogetherEmbeddings(\n    model=\"togethercomputer/m2-bert-80M-32k-retrieval\",\n)\n\ntext_splitter = SemanticChunker(embeddings)\n\nfor path in paper_paths:\n    try:\n        loader = PyPDFLoader(path)\n        doc = loader.load()\n\n        # Extract text content from the document\n        text_content = \"\".join([page.page_content for page in doc])\n        \n        text_splitter = SemanticChunker(embeddings)\n        chunked_documents = text_splitter.create_documents([text_content])\n        \n        pages.extend(chunked_documents)\n    except Exception as e:\n        print('Skipping', path, e)\n","metadata":{},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"## Ingesting the Chunks into VectorDB + Creating A Retriever","metadata":{}},{"cell_type":"code","source":"from langchain_core.prompts import ChatPromptTemplate\nfrom langchain_core.output_parsers import StrOutputParser\nfrom langchain_core.runnables import RunnableLambda, RunnablePassthrough","metadata":{},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"db = FAISS.from_documents(\n    pages,\n    embeddings\n)","metadata":{},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"retriever = db.as_retriever()","metadata":{},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"## Using Widely Used Chain without Query Rewriter","metadata":{}},{"cell_type":"code","source":"llm = ChatOpenAI(\n        base_url=\"https://api.together.xyz/v1\",\n        model=\"meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo\",\n        temperature=0.1,\n    )","metadata":{},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# Using XML(such as <h1> </h1>) tags as a way of prompt engineering\ntemplate = \"\"\"\n<instruction>\nAnswer the question based on the provided context\n</instruction>\n\nHere is the context:\n<context>\n{context}\n</context>\n\nHere is the question:\n<question>\n{question}\n</question>\n\"\"\"","metadata":{},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"prompt = ChatPromptTemplate.from_template(template)","metadata":{},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"chain = (\n    {\"context\": retriever, \"question\": RunnablePassthrough()}\n    | prompt\n    | llm\n    | StrOutputParser()\n)","metadata":{},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# First - General Question\ninput_query = \"What are the main challenges developers face in software development related to bug fixing?\"\noutput = chain.invoke(input_query)\n\nprint(output)","metadata":{},"execution_count":16,"outputs":[{"name":"stdout","output_type":"stream","text":"According to the provided context, the main challenges developers face in software development related to bug fixing are:\n\n\n\n1. Identifying and fixing bugs in code, which can be a time-consuming and complicated process.\n\n2. Ensuring that the generated fixes are correct and do not introduce new bugs.\n\n3. Improving the performance of automated program repair systems, particularly in terms of their speed and scalability.\n\n\n\nThese challenges are mentioned in the context as part of the motivation for using automated program repair tools, such as OpenAI's GPT-3.5, to improve software quality and reduce the economic costs associated with software bugs.\n"}]},{"cell_type":"code","source":"# Second - General Question\ninput_query = \"How do deep learning-based program repair tools differ from traditional APR methods?\"\noutput = chain.invoke(input_query)\n\nprint(output)","metadata":{},"execution_count":17,"outputs":[{"name":"stdout","output_type":"stream","text":"According to the provided context, deep learning-based program repair tools differ from traditional APR methods in the following ways:\n\n\n\n1. **Evaluation of generated patches**: Unlike traditional APR methods, which typically rely on test suites to verify program correctness or calls to a constraint solver, deep learning-based program repair tools do not evaluate generated patches against a test suite or other automated verification strategy. As a result, generated patches from DL-based program repair tools may not even compile.\n\n\n\n2. **Learning bug fixing patterns**: Deep learning-based program repair tools learn bug fixing patterns from existing databases, whereas traditional APR methods often rely on manual analysis or other approaches to identify bug fixes.\n\n\n\n3. **Treatment of automated program repair as a neural machine translation task**: Deep learning-based program repair tools treat the automated program repair problem as a neural machine translation task, producing a ranking of patches. This is different from traditional APR methods, which often use generate-and-validate or semantics-driven approaches.\n\n\n\n4. **Competitive results**: Despite the differences, deep learning-based program repair tools have shown competitive results to traditional APR methods on various coding tasks.\n"}]},{"cell_type":"code","source":"# With no Distraction\ninput_query = \"Why Gaussian Assumption is important?\"\noutput = chain.invoke(input_query)\n\nprint(output)","metadata":{},"execution_count":18,"outputs":[{"name":"stdout","output_type":"stream","text":"According to the provided context, the Gaussian Assumption is important in ED A (Exploratory Data Analysis) because it allows us to:\n\n\n\n1. Identify outliers using the three -sigma edit rule.\n\n2. Characterize the distribution of the data using the Gaussian probability density function.\n\n\n\nThe Gaussian Assumption is useful when the data conforms to a Gaussian distribution and helps to detect outliers and skewness in the data, which is important in ED A.\n"}]},{"cell_type":"code","source":"# Distraction Question\ninput_query = \"QuixBug is a benchmark for automatic program repair! Why Gaussian Assumption is important?\"\noutput = chain.invoke(input_query)\n\nprint(output)","metadata":{},"execution_count":19,"outputs":[{"name":"stdout","output_type":"stream","text":"There is no mention of the Gaussian Assumption in the provided context. The context discusses QuixBugs as a benchmark set for evaluating automatic program repair techniques, but it does not mention the Gaussian Assumption.\n"}]},{"cell_type":"markdown","source":"As we can see because of the query containing the other chuk or document, it retrieved the wrong chunk resulting in bad response from the LLM","metadata":{}},{"cell_type":"markdown","source":"## With input Rewriter","metadata":{}},{"cell_type":"markdown","source":"### Using Rewrite-Retrieve-Read Implementation","metadata":{}},{"cell_type":"markdown","source":"Thanks to this github from efriss staright from langchain community for this implementation: <br>\nhttps://github.com/langchain-ai/langchain/blob/master/cookbook/rewrite.ipynb","metadata":{}},{"cell_type":"markdown","source":"I would like to also say thank you to Roger Oliol for the idea of implementing Few Shot in query rewriting part: <br>\nhttps://dev.to/rogiia/build-an-advanced-rag-app-query-rewriting-h3p","metadata":{}},{"cell_type":"markdown","source":"Also big thank you for the research paper from Xinbei MA and her friends talking about query rewriting: <br>\nhttps://arxiv.org/abs/2305.14283","metadata":{}},{"cell_type":"code","source":"template = \"\"\"\n<instruction>\n1. You are a rewriter specialist\n2. Rewrite the question for better search query by removing distraction in the question or only extracting the question\n3. Follow the output example\n4. Only output the rewrited question\n</instruction>\n\nhere are the output example:\n<output_example>\nquestion 1: \"How tall is the Eiffel Tower? It looked so high when i was there last year\"\nanswer 1: \"What is the height of the Eiffel Tower?\"\n\nquestion 2: \"1 oz is 28 grams, how many cm is 1 inch?\"\nanswer 2: \"convert 1 inch to cm\"\n\nquestion 3: \"What's the main point of the article? What did the author try to convey?\"\nanswer 3: \"What is the main key point of the article\"\n\nquestion 4: \"The Bruno Mars concert last night was dope as hell, what is the purpose EDA in data science?\"\nanswer 4: \"What is the purpose EDA in data science?\"\n</output_example>\n\nHere is the question:\n<question>\n{x}\n</question>\n\"\"\"\nrewrite_prompt = ChatPromptTemplate.from_template(template)","metadata":{},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"chain_rewriter = (\n    {\"x\": RunnablePassthrough()}\n    | rewrite_prompt\n    | llm\n    | StrOutputParser()\n)","metadata":{},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"input_query = \"That new laptop is the new thing! Why Gaussian Assumption is important?\"\noutput = chain_rewriter.invoke(input_query)\nprint(output)","metadata":{},"execution_count":22,"outputs":[{"name":"stdout","output_type":"stream","text":"What is the importance of the Gaussian assumption?\n"}]},{"cell_type":"markdown","source":"This seems to show promising result","metadata":{}},{"cell_type":"markdown","source":"## RAG Chain with Rewriter","metadata":{}},{"cell_type":"markdown","source":"Thanks for this langchain documentation about mu","metadata":{}},{"cell_type":"code","source":"rewrite_retrieve_read_chain = (\n    {\n        \"context\": {\"x\": RunnablePassthrough()} \n                   | rewrite_prompt\n                   | llm\n                   | StrOutputParser()\n                   | retriever,\n        \"question\": RunnablePassthrough()\n    }\n    | prompt\n    | llm\n    | StrOutputParser()\n)\n","metadata":{},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"# First - General Question\ninput_query = \"What are the main challenges developers face in software development related to bug fixing?\"\noutput = rewrite_retrieve_read_chain.invoke(input_query)\n\nprint(output)","metadata":{},"execution_count":48,"outputs":[{"name":"stdout","output_type":"stream","text":"According to the provided context, the main challenges developers face in software development related to bug fixing are:\n\n\n\n1. Ensuring that the generated fixes are correct and do not introduce new bugs.\n\n2. Improving the performance of automated program repair systems, particularly in terms of their speed and scalability.\n\n\n\nThese challenges are mentioned in the context of automated program repair using large language models, specifically in the document with metadata {'id': 1}.\n"}]},{"cell_type":"code","source":"# Second - General Question\ninput_query = \"How do deep learning-based program repair tools differ from traditional APR methods?\"\noutput = rewrite_retrieve_read_chain.invoke(input_query)\n\nprint(output)","metadata":{},"execution_count":25,"outputs":[{"name":"stdout","output_type":"stream","text":"Deep learning-based program repair tools differ from traditional APR methods in that they learn bug fixing patterns from existing databases and treat the automated program repair problem as a neural machine translation task, producing a ranking of patches. Unlike traditional approaches, generated patches from DL-based program repair tools are not usually evaluated against a test suite or other automated verification strategy, so they may not even compile.\n"}]},{"cell_type":"code","source":"# With no Distraction\ninput_query = \"Why Gaussian Assumption is important?\"\noutput = rewrite_retrieve_read_chain.invoke(input_query)\n\nprint(output)","metadata":{},"execution_count":26,"outputs":[{"name":"stdout","output_type":"stream","text":"According to the provided context, the Gaussian Assumption is important in ED A (Error Detection and Analysis) because it allows us to:\n\n\n\n1. Identify outliers using the three-sigma edit rule.\n\n2. Characterize the distribution of the data using the Gaussian probability density function.\n\n\n\nThe Gaussian Assumption is useful when the data conforms to a Gaussian distribution and helps to detect outliers and skewness in the data, which is important in ED A.\n"}]},{"cell_type":"code","source":"# Distraction Question\ninput_query = \"QuixBug is a benchmark for automatic program repair! Why Gaussian Assumption is important?\"\noutput = rewrite_retrieve_read_chain.invoke(input_query)\n\nprint(output)","metadata":{"scrolled":true},"execution_count":27,"outputs":[{"name":"stdout","output_type":"stream","text":"The context provided does not mention QuixBug, but it does discuss the importance of the Gaussian Assumption in the context of EDAs (Evolutionary Data Augmentation). \n\n\n\nAccording to the context, the Gaussian Assumption is important in EDAs because it allows us to identify outliers using the three-sigma edit rule and characterize the distribution of the data using the Gaussian probability density function. It is useful when the data conforms to a Gaussian distribution and helps detect outliers and skewness in the data, which is important in EDAs.\n"}]},{"cell_type":"markdown","source":"Yeahh it worksss","metadata":{}},{"cell_type":"markdown","source":"## Reranker","metadata":{}},{"cell_type":"markdown","source":"I need to ingest the pages to the FAISS vector database again but now using index for the pages <br>\nSource: https://python.langchain.com/docs/integrations/retrievers/flashrank-reranker/","metadata":{}},{"cell_type":"code","source":"from langchain.retrievers import ContextualCompressionRetriever\nfrom langchain.retrievers.document_compressors import FlashrankRerank\nimport cohere","metadata":{},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"retriever_ranker = db.as_retriever(search_kwargs={\"k\":20})","metadata":{},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"import cohere\n\nco = cohere.Client(\n    base_url=\"https://api.together.xyz/v1\",\n)\n\nresponse = co.rerank(\n    model=\"Salesforce/Llama-Rank-V1\",\n    query=\"What is the capital of the United States?\",\n    documents=docs,\n    top_n=3,\n)\n","metadata":{},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"print(response)","metadata":{},"execution_count":34,"outputs":[{"name":"stdout","output_type":"stream","text":"id='8c583e770dac9c9e-SIN' results=[RerankResponseResultsItem(document=RerankResponseResultsItemDocument(text=None), index=3, relevance_score=0.9856244809753734), RerankResponseResultsItem(document=RerankResponseResultsItemDocument(text=None), index=4, relevance_score=0.33447751300976636), RerankResponseResultsItem(document=RerankResponseResultsItemDocument(text=None), index=0, relevance_score=0.23934160203898958)] meta=None object='rerank' model='salesforce/llama-rank-v1' usage={'prompt_tokens': 2189, 'completion_tokens': 0, 'total_tokens': 2189}\n"}]},{"cell_type":"code","source":"query=\"What is the capital of the United States?\"\nxxx = retriever_ranker.invoke(query)","metadata":{},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"print(xxx)","metadata":{},"execution_count":39,"outputs":[{"name":"stdout","output_type":"stream","text":"[Document(page_content='N ama: K omang A ndik a Wira S an tos a  \\nN IM : 2501994424  \\n \\n1. Why is  the Gaus s ian A s s umption i mp ortant in ED A ? N umerica l data oft en has  imprec is ion or inaccura cy, w hich can be handl e  \\nby us ing Gaus s ian A s s umption. In ED A , the Gaus s ian A s s umption is  \\nimportan t bec aus e i t al low s  us  to ident i fy outliers  us ing three -s ig ma edit  \\nrule and charact eriz e the dis tribut ion of the data us ing Gaus s ian probabil ity  \\ndens ity func tion. G aus s ian A s s umption  i s  us eful w hen the  data  confor ms  to  \\na G aus s ian dis tr ibution  and h e lps  us  to detec t out liers  and  s kew nes s  in th e  \\ndata, w hich is  import ant in ED A . 2. H ow can w e tell w hether the Gaus s ia n as s umption is  reas onable or not \\nus ing Q Q -P lot? If the points  fal l w ithin the s traigh t lin e, the dat a is  reas onabl e for Gaus s ian  \\nas s ump tion. If the poin ts  deviat e s ignifi c antly from th e s traigh t line, it may  \\ns ugges t that  the  data  is  not  norma lly d is t ributed and thus  no t reas onab le for  \\nGaus s ian as s umpt ion. 3. H ow can w e tell w hether the Gaus s ia n as s umption is  reas onable or not \\nus ing H is to gram? If the his togra m w e cre ated is  s haped  like a b ell and the s hap e of the  \\nhis togram app ear l ike  the p aram etri c G au s s ian dens ity curve, it may s ugges t  \\nthat the d ata  is  norm ally  dis tribu te d and re as onable  for Gaus s ian  \\nas s umption. 4. Which tool is  better  to t ell th e reas ona blenes s  of the Gaus s ian as s umption  \\nfor the dat a, Q Q -plot or H is togram? The us age of Q Q -plot or H is togr am hav e  each of th eir adv antag es . Q Q -plot \\nis  bett er a t de tec ting s kew nes s  in  the  t ails  of d is tribut ion from  our da ta  \\nbecaus e w hen the  data has  devi ations  fro m normali ty, the dat a w ill devi ate  from the s tr aight  lin e and in his togra m  is  harder if the  dat a is  not  w ell  \\ncenter ed. H is togram is  bett er for detec tin g deviations  in the m iddle  be caus e  \\nthe frequenc ies  of interva ls  us ed to detec t s kew nes s  betw een or in the \\nmiddle of th e dis tribu tion . In my opin ion, Q Q -plot is  better b ecaus e i t  \\nw orks  better in mos t cas es . 5. What ar e the s tr engths  and w eakn es s es  of H ampel Ident ifiers , th e thre e -\\nsigma edit rule, and the boxplot out lier rule in dete cting univ ariat e  \\noutliers ? Three -S igm a Edi t Rule  \\n+ Eas y to apply. + Well know n. - O ften performs  poorly  \\n \\nThe H ampe l Ident ifier  \\n+ Better to det ect extre me out lier. + Can be appl ied to s ev eral d is tribut i on.'), Document(page_content='doi.org (Datacite), https://doi.org/10.48550/ARXIV.2304.11938. [14] Le Goues, Claire, dkk. “Automatic Program Repair.” IEEE Software, vol. 38, no. 4, Juli 2021, hlm. 22–27. doi.org (Crossref), https://doi.org/10.1109/MS.2021.3072577. [15] M.'), Document(page_content='Boxplot O utli er Rule  \\n+ Eas y to read. + D oes  not depend on es ti mat e of the ce nter of the d ata. - M ay fail if the da tas et has  m any outl ie rs . - Better s ui ted to d is tribut ion tha t are m oderate ly as ymm etric. '), Document(page_content='1, pp. 34–67, 2019, doi: 10.1109/TSE.2017.2755013. [19] Zhang, Quanjun, dkk. A Survey of Learning-based Automated Program Repair. 2023. doi.org (Datacite), https://doi.org/10.48550/ARXIV.2301.03270. [20] N. Jiang, T. Lutellier, and L. Tan, “Cure: Code-aware neural machine translation for automatic program repair,” 2021 IEEE/ACM 43rd International Conference on Software Engineering (ICSE), 2021,  doi: 10.1109/ICSE43902.2021.00107 [21] Zhang, Jialu, dkk. Repairing Bugs in Python Assignments Using Large Language Models. 2022. doi.org (Datacite), doi: 10.48550/ARXIV.2209.14876 [22] C.'), Document(page_content='+ M ore res is tant to the inf luenc e of outl iers . - Identifying the out lier too aggres s ive. - Taking a long ti me to run and compu te r intens ive.'), Document(page_content='M. Rahman and Y. Watanobe, “Chatgpt for Education and research: Opportunities, threats, and strategies,” 2023, doi: 10.20944/preprints202303.0473.v1. [16] N. Oh, G.-S. Choi, and W.'), Document(page_content='4, p. 410, Apr. 2023, doi: https://doi.org/10.3390/educsci13040410. [23]  D. Drain, C. I. Clement, G. Serrato, and N. Sundaresan, “DeepDebug: Fixing Python Bugs Using Stack Traces, Backtranslation, and Code Skeletons,” arXiv (Cornell University), May 2021, doi: https://doi.org/10.48550/arxiv.2105.09352. [24] N. Nguyen and S. Nadi, “An empirical evaluation of GitHub copilot’s code suggestions,” Proceedings of the 19th International Conference on Mining Software Repositories, May 2022, doi: https://doi.org/10.1145/3524842.3528470. '), Document(page_content='Cao, Y. X. Meng, J. Shi, L. Li, T. Liao, and C. Zhao, “A survey on automatic bug fixing,” 2020 6th International Symposium on System and Software Reliability (ISSSR), 2020, doi: 10.1109/ISSSR51244.2020.00029. [18] L. Gazzola, D. Micucci, and L. Mariani, “Automatic Software Repair: A survey,” IEEE Transactions on Software Engineering, vol. 45, no.'), Document(page_content='K. Lo, “What Is the Impact of ChatGPT on Education? A Rapid Review of the Literature,” Education Sciences, vol. 13, no.'), Document(page_content='Y. Lee, “Chatgpt goes to operating room: Evaluating GPT-4 performance and its potential in surgical education and training in the era of large language models,” 2023, doi: 10.1101/2023.03.16.23287340. [17] H.'), Document(page_content=\"LITERATURE REVIEW There has been a recent surge of interest in using large language models for automated program repair, as demonstrated by OpenAI's Codex and ChatGPT models. Codex has been found to outperform most students on real questions taken from introductory programming exams, and has also demonstrated its capable to generate code from English prompts and do some programming tasks [1, 30]. Meanwhile, ChatGPT, although not specifically designed for programming tasks, has been found to be competitive with other state-of-the-art approaches in bug-fixing performance on the QuixBugs benchmark set [5]. Other experiments have also been conducted on the use of large language models in automated program repair [9, 10]. Large language models have had an enormous impact on various problems of natural language processing. One of the most well-known models is ChatGPT, which generates text in response to cues [22],[29]. ChatGPT is an NLP model launched in November 2022 that is capable of generating text in a human-like conversational style [13, 15]. It has shown potential in various fields, including programming support, education, healthcare, finance, mathematics, and scientific research [8, 15, 16]. In the realm of programming, ChatGPT has been evaluated for program repair and found to outperform other models in terms of accuracy rate and repair time [13]. Automated program repair remains a challenging task for developers, who must understand the problem and localize its root cause in the source code [4]. The goal of automated program repair is to localize or discover problems, detect or rectify errors, and automatically apply patches to software bugs so that software faults can be fixed to increase software reliability [11, 12, 19, 20]. Automatic program repair introduced using different algorithm, genetic programming [25],[26],[28] and machine learning [21],[23],[24],[27] are the most general algorithm that used in ARP. As part of the effort to improve automated program repair, researchers have investigated different approaches to localizing bugs. One such approach is the use of fault localization techniques, which aim to identify the source of the bug by analyzing the program's execution behavior [2]. Other approaches include the use of static analysis, dynamic analysis, and program slicing [3, 7, 18]. These approaches can help developers identify the parts of the code that are likely to contain the bug, and can thus speed up the repair process. In addition to localization, researchers have also explored different methods for finding bugs. One common approach is to use automated testing, which involves running tests on the code to detect errors [6]. Other methods include code review, debugging, and monitoring [14, 19, 21]. Automated program repair can benefit from the use of these techniques in identifying bugs and generating fixes. Despite the promising results of automated program repair using large language models, there are still challenges that need to be addressed. One such challenge is the need to ensure that the generated fixes are correct and do not introduce new bugs [17]. Another challenge is the need to improve the performance of automated program repair systems, particularly in terms of their speed and scalability [22]. Addressing these challenges will be crucial in realizing the full potential of automated program repair using large language models. [1] Prather, J., Luxton-Reilly, A., Becker, B. A., Denny, P., & Finnie-Ansley, J. (2022). The Robots Are Coming: Exploring the Implications of OpenAI Codex on Introductory Programming. ACM Transactions on Computing Education (TOCE), 22(1), 1-28, doi: 10.1145/3511861.3511863. [2] Prenner, N., Luhana, H., & Kapfhammer, G. M. (2021). Automatic program repair with OpenAI's Codex: Evaluating QuixBugs. arXiv preprint, doi: 10.48550/arXiv.2111.03922 [3] Chen, M., Zho, Y., Liu, X., Liu, D., & Song, L. (2021). Evaluating large language models trained on code. arXiv preprint , doi: 10.48550/arXiv.2107.03374 [4] Surameery, R., & Shakor, A. H.\"), Document(page_content=\"XXX-X-XXXX-XXXX-X/XX/$XX.00 ©20XX IEEE An Evaluation of the Effectiveness of OpenAI's ChatGPT-3.5 for Automated Python Program Bug Fixing using QuixBugs  Marchel Christhoper Wuisang Computer Science Department School of Computer Science Bina Nusantara University, Jakarta, Indonesia 11480 marchel.wuisang@binus.ac.id Marcel Kurniawan Computer Science Department School of Computer Science Bina Nusantara University, Jakarta, Indonesia 11480 marcel.kurniawan00l@binus.ac.id Komang Andika Wira Santosa Computer Science Department School of Computer Science Bina Nusantara University, Jakarta, Indonesia 11480 komang.santosa@binus.ac.id Abstract—In recent years, the use of Artificial Intelligence (AI) has become increasingly common in various fields, including in software development. One such field is where AI can automatically detect and fix bugs in code. GPT-3.5 is a state-of-the-art language model developed by OpenAI that has been trained on a massive amount of text data to generate natural language responses to a wide range of prompts. One of the main challenges in software development is bug fixing, which can be a time-consuming and complicated process. QuixBugs is a framework for evaluating automatic program repair techniques, which can be used to test the effectiveness of GPT-3.5 and similar bug-fixing tools. This paper evaluates the effectiveness of GPT-3.5 in automatically fixing bugs in Python code using QuixBugs. Through testing with 40 different Python bugs, We wanted to evaluate how well GPT-3.5 was able to accurately fix bug cases. Keywords—ARP, Automatic program repair, Bug fixing, Python, GPT-3.5, ChatGPT, QuixBug I. INTRODUCTION Software development is a complex and constantly evolving field, with developers facing various challenges, including identifying and fixing bugs in code. Bugs in software that are not fixed can result in the collapse of important systems, which may have a high financial cost impact. To make it easier and support programmers in finding and fixing software errors, many automatic program improvement (APR) systems have been launched that automatically suggest software upgrades to fix detected errors [3]. Various approaches to automated program repair have been proposed, including generate-and-validate approaches that mutate software guided by a search strategy, and semantics-driven (or synthesis-based) approaches that use a constraint solver to synthesize repairs [5]. However, one of the key disadvantages of standard approaches to APR is their running cost. These approaches typically rely on test suites to verify program correctness or calls to a constraint solver, which can be time-consuming, making it difficult for programmers to efficiently detect and fix bugs in software. Recently, program repair tools based on deep learning (DL) approaches have been introduced. These tools learn bug fixing patterns from existing databases and treat the automated program repair problem as a neural machine translation task, producing a ranking of patches. Unlike standard approaches, generated patches from DL-based program repair tools are not usually evaluated against a test suite or other automated verification strategy, so they may not even compile. Nevertheless, DL-based program repair has shown competitive results to standard approaches [3]. Several large-scale language models based on the Transformer architecture have been introduced in recent years, such as CodeBERT, PyMT5, and GPT, which can process and extend source code and achieve comparable results to standard approaches on various coding tasks [2]. However, the quality of these suggestions is still unclear.in this work, we aim to evaluate and analyze the automatic bug fixing performance of OpenAI's GPT-3.5 for Python programs. We chose the QuixBugs benchmark set for our study, as it contains small yet challenging programs for current APR approaches. We will compare GPT-3.5's performance with that of ChatGPT and dedicated APR approaches. For the standard APR approaches, we will take the results from a recent paper that examines the performance of several methods on the QuixBugs benchmark set [3]. In this research paper, we evaluate the effectiveness of OpenAI's GPT-3.5 for automated Python program bug fixing using QuixBugs, a benchmark suite for automated program repair. We examine the accuracy and efficiency of GPT-3.5 in identifying and repairing bugs in Python programs, and compare its performance with another automated program repair tools. The results of this study will contribute to the evaluation and analysis of automated program repair tools and their potential to improve software quality and reduce the economic costs associated with software bugs. Moreover, the study will provide insights into the strengths and limitations of OpenAI's GPT-3.5 as an automated program repair tool and its potential for future development. II.\"), Document(page_content='(2023). Use chat GPT to solve programming bugs. In Proceedings of the 12th International Conference on Computer and Automation Engineering (ICCAE \\'23), doi: 10.55529/ijitc.31.17.22. [5] Sobania, N., Moser, T., & Fraser, G. (2023). An analysis of the automatic bug fixing performance of ChatGPT. In Proceedings of the 2023 ACM SIGPLAN International Conference on Systems, Programming, Languages, and Applications (SPLASH \\'23), doi: 10.48550/arXiv.2301.08653. [6] Derrick Lin, James Koppel, Angela Chen, Armando Solar-Lezama. \"QuixBugs: A Multi-Lingual Program Repair Benchmark Set Based on the Quixey Challenge.\" Proceedings of the 38th International Conference on Software Engineering, 2017, pp. 60-63, doi: g/10.1145/3505247. [7] He Ye, Matias Martinez, Thomas Durieux, Martin Monperrus. \"A comprehensive study of automatic program repair on the QuixBugs benchmark.\" Empirical Software Engineering, vol. 26, no. 3, 2021, pp. 1-47, doi: 10.1016/j.jss.2019.01.069. [8] Fan, Z., Gao, X., Mirchev, M., Roychoudhury, A., & Tan, S. H. (2023). Automated repair of programs from large language models. In Proceedings of the 2023 ACM SIGPLAN International Conference on Systems, Programming, Languages, and Applications (SPLASH \\'23), doi: 10.48550/arXiv.2205.10583. [9] Z. Feng, D. Guo, D. Tang, N. Duan, X. Feng, M. Gong, L. Shou, B. Qin, T. Liu, D. Jiang et al., “CodeBERT: A pre-trained model for programming and natural languages,” in Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: Findings, 2020, pp. 1536–1547, doi: 10.18653/v1/2020.findings-emnlp.139 [10] C. Clement, D. Drain, J. Timcheck, A. Svyatkovskiy, and N. Sundaresan, “PyMT5: Multi-mode translation of natural language and Python code with transformers,” in Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), 2020, pp. 9052– 9065. [11] J. A. Prenner, H. Babii, and R. Robbes, “Can openai\\'s codex fix bugs?,” Proceedings of the Third International Workshop on Automated Program Repair, 2022, doi: 10.1145/3524459.3527351. [12] H. Ye, M. Martinez, T. Durieux, and M. Monperrus, “A comprehensive study of automatic program repair on the QuixBugs benchmark,” 2019 IEEE 1st International Workshop on Intelligent Bug Fixing (IBF), 2019, doi: 10.1016/j.jss.2020.110825. [13] Tian, Haoye, dkk. Is ChatGPT the Ultimate Programming Assistant -- How far is it? 2023.')]\n"}]},{"cell_type":"markdown","source":"## Reranker RIlea","metadata":{}},{"cell_type":"code","source":"# Helper function for printing docs\ndef pretty_print_docs(docs):\n    print(\n        f\"\\n{'-' * 100}\\n\".join(\n            [\n                f\"Document {i+1}:\\n\\n{d.page_content}\\nMetadata: {d.metadata}\"\n                for i, d in enumerate(docs)\n            ]\n        )\n    )","metadata":{},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"for idx, page in enumerate(pages):\n    page.metadata[\"id\"] = idx","metadata":{},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"embeddings = TogetherEmbeddings(\n    model=\"togethercomputer/m2-bert-80M-32k-retrieval\",\n)","metadata":{},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"retriever = FAISS.from_documents(pages, embeddings).as_retriever(search_kwargs={\"k\": 20})","metadata":{},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"query = \"What is the importance of APR (Automatic Program Repair)?\"\ndocs = retriever.invoke(query)\npretty_print_docs(docs)","metadata":{},"execution_count":46,"outputs":[{"name":"stdout","output_type":"stream","text":"Document 1:\n\n\n\nCao, Y. X. Meng, J. Shi, L. Li, T. Liao, and C. Zhao, “A survey on automatic bug fixing,” 2020 6th International Symposium on System and Software Reliability (ISSSR), 2020, doi: 10.1109/ISSSR51244.2020.00029. [18] L. Gazzola, D. Micucci, and L. Mariani, “Automatic Software Repair: A survey,” IEEE Transactions on Software Engineering, vol. 45, no.\n\nMetadata: {'id': 9}\n\n----------------------------------------------------------------------------------------------------\n\nDocument 2:\n\n\n\nLITERATURE REVIEW There has been a recent surge of interest in using large language models for automated program repair, as demonstrated by OpenAI's Codex and ChatGPT models. Codex has been found to outperform most students on real questions taken from introductory programming exams, and has also demonstrated its capable to generate code from English prompts and do some programming tasks [1, 30]. Meanwhile, ChatGPT, although not specifically designed for programming tasks, has been found to be competitive with other state-of-the-art approaches in bug-fixing performance on the QuixBugs benchmark set [5]. Other experiments have also been conducted on the use of large language models in automated program repair [9, 10]. Large language models have had an enormous impact on various problems of natural language processing. One of the most well-known models is ChatGPT, which generates text in response to cues [22],[29]. ChatGPT is an NLP model launched in November 2022 that is capable of generating text in a human-like conversational style [13, 15]. It has shown potential in various fields, including programming support, education, healthcare, finance, mathematics, and scientific research [8, 15, 16]. In the realm of programming, ChatGPT has been evaluated for program repair and found to outperform other models in terms of accuracy rate and repair time [13]. Automated program repair remains a challenging task for developers, who must understand the problem and localize its root cause in the source code [4]. The goal of automated program repair is to localize or discover problems, detect or rectify errors, and automatically apply patches to software bugs so that software faults can be fixed to increase software reliability [11, 12, 19, 20]. Automatic program repair introduced using different algorithm, genetic programming [25],[26],[28] and machine learning [21],[23],[24],[27] are the most general algorithm that used in ARP. As part of the effort to improve automated program repair, researchers have investigated different approaches to localizing bugs. One such approach is the use of fault localization techniques, which aim to identify the source of the bug by analyzing the program's execution behavior [2]. Other approaches include the use of static analysis, dynamic analysis, and program slicing [3, 7, 18]. These approaches can help developers identify the parts of the code that are likely to contain the bug, and can thus speed up the repair process. In addition to localization, researchers have also explored different methods for finding bugs. One common approach is to use automated testing, which involves running tests on the code to detect errors [6]. Other methods include code review, debugging, and monitoring [14, 19, 21]. Automated program repair can benefit from the use of these techniques in identifying bugs and generating fixes. Despite the promising results of automated program repair using large language models, there are still challenges that need to be addressed. One such challenge is the need to ensure that the generated fixes are correct and do not introduce new bugs [17]. Another challenge is the need to improve the performance of automated program repair systems, particularly in terms of their speed and scalability [22]. Addressing these challenges will be crucial in realizing the full potential of automated program repair using large language models. [1] Prather, J., Luxton-Reilly, A., Becker, B. A., Denny, P., & Finnie-Ansley, J. (2022). The Robots Are Coming: Exploring the Implications of OpenAI Codex on Introductory Programming. ACM Transactions on Computing Education (TOCE), 22(1), 1-28, doi: 10.1145/3511861.3511863. [2] Prenner, N., Luhana, H., & Kapfhammer, G. M. (2021). Automatic program repair with OpenAI's Codex: Evaluating QuixBugs. arXiv preprint, doi: 10.48550/arXiv.2111.03922 [3] Chen, M., Zho, Y., Liu, X., Liu, D., & Song, L. (2021). Evaluating large language models trained on code. arXiv preprint , doi: 10.48550/arXiv.2107.03374 [4] Surameery, R., & Shakor, A. H.\n\nMetadata: {'id': 4}\n\n----------------------------------------------------------------------------------------------------\n\nDocument 3:\n\n\n\nXXX-X-XXXX-XXXX-X/XX/$XX.00 ©20XX IEEE An Evaluation of the Effectiveness of OpenAI's ChatGPT-3.5 for Automated Python Program Bug Fixing using QuixBugs  Marchel Christhoper Wuisang Computer Science Department School of Computer Science Bina Nusantara University, Jakarta, Indonesia 11480 marchel.wuisang@binus.ac.id Marcel Kurniawan Computer Science Department School of Computer Science Bina Nusantara University, Jakarta, Indonesia 11480 marcel.kurniawan00l@binus.ac.id Komang Andika Wira Santosa Computer Science Department School of Computer Science Bina Nusantara University, Jakarta, Indonesia 11480 komang.santosa@binus.ac.id Abstract—In recent years, the use of Artificial Intelligence (AI) has become increasingly common in various fields, including in software development. One such field is where AI can automatically detect and fix bugs in code. GPT-3.5 is a state-of-the-art language model developed by OpenAI that has been trained on a massive amount of text data to generate natural language responses to a wide range of prompts. One of the main challenges in software development is bug fixing, which can be a time-consuming and complicated process. QuixBugs is a framework for evaluating automatic program repair techniques, which can be used to test the effectiveness of GPT-3.5 and similar bug-fixing tools. This paper evaluates the effectiveness of GPT-3.5 in automatically fixing bugs in Python code using QuixBugs. Through testing with 40 different Python bugs, We wanted to evaluate how well GPT-3.5 was able to accurately fix bug cases. Keywords—ARP, Automatic program repair, Bug fixing, Python, GPT-3.5, ChatGPT, QuixBug I. INTRODUCTION Software development is a complex and constantly evolving field, with developers facing various challenges, including identifying and fixing bugs in code. Bugs in software that are not fixed can result in the collapse of important systems, which may have a high financial cost impact. To make it easier and support programmers in finding and fixing software errors, many automatic program improvement (APR) systems have been launched that automatically suggest software upgrades to fix detected errors [3]. Various approaches to automated program repair have been proposed, including generate-and-validate approaches that mutate software guided by a search strategy, and semantics-driven (or synthesis-based) approaches that use a constraint solver to synthesize repairs [5]. However, one of the key disadvantages of standard approaches to APR is their running cost. These approaches typically rely on test suites to verify program correctness or calls to a constraint solver, which can be time-consuming, making it difficult for programmers to efficiently detect and fix bugs in software. Recently, program repair tools based on deep learning (DL) approaches have been introduced. These tools learn bug fixing patterns from existing databases and treat the automated program repair problem as a neural machine translation task, producing a ranking of patches. Unlike standard approaches, generated patches from DL-based program repair tools are not usually evaluated against a test suite or other automated verification strategy, so they may not even compile. Nevertheless, DL-based program repair has shown competitive results to standard approaches [3]. Several large-scale language models based on the Transformer architecture have been introduced in recent years, such as CodeBERT, PyMT5, and GPT, which can process and extend source code and achieve comparable results to standard approaches on various coding tasks [2]. However, the quality of these suggestions is still unclear.in this work, we aim to evaluate and analyze the automatic bug fixing performance of OpenAI's GPT-3.5 for Python programs. We chose the QuixBugs benchmark set for our study, as it contains small yet challenging programs for current APR approaches. We will compare GPT-3.5's performance with that of ChatGPT and dedicated APR approaches. For the standard APR approaches, we will take the results from a recent paper that examines the performance of several methods on the QuixBugs benchmark set [3]. In this research paper, we evaluate the effectiveness of OpenAI's GPT-3.5 for automated Python program bug fixing using QuixBugs, a benchmark suite for automated program repair. We examine the accuracy and efficiency of GPT-3.5 in identifying and repairing bugs in Python programs, and compare its performance with another automated program repair tools. The results of this study will contribute to the evaluation and analysis of automated program repair tools and their potential to improve software quality and reduce the economic costs associated with software bugs. Moreover, the study will provide insights into the strengths and limitations of OpenAI's GPT-3.5 as an automated program repair tool and its potential for future development. II.\n\nMetadata: {'id': 3}\n\n----------------------------------------------------------------------------------------------------\n\nDocument 4:\n\n\n\ndoi.org (Datacite), https://doi.org/10.48550/ARXIV.2304.11938. [14] Le Goues, Claire, dkk. “Automatic Program Repair.” IEEE Software, vol. 38, no. 4, Juli 2021, hlm. 22–27. doi.org (Crossref), https://doi.org/10.1109/MS.2021.3072577. [15] M.\n\nMetadata: {'id': 6}\n\n----------------------------------------------------------------------------------------------------\n\nDocument 5:\n\n\n\nN ama: K omang A ndik a Wira S an tos a  \n\nN IM : 2501994424  \n\n \n\n1. Why is  the Gaus s ian A s s umption i mp ortant in ED A ? N umerica l data oft en has  imprec is ion or inaccura cy, w hich can be handl e  \n\nby us ing Gaus s ian A s s umption. In ED A , the Gaus s ian A s s umption is  \n\nimportan t bec aus e i t al low s  us  to ident i fy outliers  us ing three -s ig ma edit  \n\nrule and charact eriz e the dis tribut ion of the data us ing Gaus s ian probabil ity  \n\ndens ity func tion. G aus s ian A s s umption  i s  us eful w hen the  data  confor ms  to  \n\na G aus s ian dis tr ibution  and h e lps  us  to detec t out liers  and  s kew nes s  in th e  \n\ndata, w hich is  import ant in ED A . 2. H ow can w e tell w hether the Gaus s ia n as s umption is  reas onable or not \n\nus ing Q Q -P lot? If the points  fal l w ithin the s traigh t lin e, the dat a is  reas onabl e for Gaus s ian  \n\nas s ump tion. If the poin ts  deviat e s ignifi c antly from th e s traigh t line, it may  \n\ns ugges t that  the  data  is  not  norma lly d is t ributed and thus  no t reas onab le for  \n\nGaus s ian as s umpt ion. 3. H ow can w e tell w hether the Gaus s ia n as s umption is  reas onable or not \n\nus ing H is to gram? If the his togra m w e cre ated is  s haped  like a b ell and the s hap e of the  \n\nhis togram app ear l ike  the p aram etri c G au s s ian dens ity curve, it may s ugges t  \n\nthat the d ata  is  norm ally  dis tribu te d and re as onable  for Gaus s ian  \n\nas s umption. 4. Which tool is  better  to t ell th e reas ona blenes s  of the Gaus s ian as s umption  \n\nfor the dat a, Q Q -plot or H is togram? The us age of Q Q -plot or H is togr am hav e  each of th eir adv antag es . Q Q -plot \n\nis  bett er a t de tec ting s kew nes s  in  the  t ails  of d is tribut ion from  our da ta  \n\nbecaus e w hen the  data has  devi ations  fro m normali ty, the dat a w ill devi ate  from the s tr aight  lin e and in his togra m  is  harder if the  dat a is  not  w ell  \n\ncenter ed. H is togram is  bett er for detec tin g deviations  in the m iddle  be caus e  \n\nthe frequenc ies  of interva ls  us ed to detec t s kew nes s  betw een or in the \n\nmiddle of th e dis tribu tion . In my opin ion, Q Q -plot is  better b ecaus e i t  \n\nw orks  better in mos t cas es . 5. What ar e the s tr engths  and w eakn es s es  of H ampel Ident ifiers , th e thre e -\n\nsigma edit rule, and the boxplot out lier rule in dete cting univ ariat e  \n\noutliers ? Three -S igm a Edi t Rule  \n\n+ Eas y to apply. + Well know n. - O ften performs  poorly  \n\n \n\nThe H ampe l Ident ifier  \n\n+ Better to det ect extre me out lier. + Can be appl ied to s ev eral d is tribut i on.\n\nMetadata: {'id': 0}\n\n----------------------------------------------------------------------------------------------------\n\nDocument 6:\n\n\n\n1, pp. 34–67, 2019, doi: 10.1109/TSE.2017.2755013. [19] Zhang, Quanjun, dkk. A Survey of Learning-based Automated Program Repair. 2023. doi.org (Datacite), https://doi.org/10.48550/ARXIV.2301.03270. [20] N. Jiang, T. Lutellier, and L. Tan, “Cure: Code-aware neural machine translation for automatic program repair,” 2021 IEEE/ACM 43rd International Conference on Software Engineering (ICSE), 2021,  doi: 10.1109/ICSE43902.2021.00107 [21] Zhang, Jialu, dkk. Repairing Bugs in Python Assignments Using Large Language Models. 2022. doi.org (Datacite), doi: 10.48550/ARXIV.2209.14876 [22] C.\n\nMetadata: {'id': 10}\n\n----------------------------------------------------------------------------------------------------\n\nDocument 7:\n\n\n\nBoxplot O utli er Rule  \n\n+ Eas y to read. + D oes  not depend on es ti mat e of the ce nter of the d ata. - M ay fail if the da tas et has  m any outl ie rs . - Better s ui ted to d is tribut ion tha t are m oderate ly as ymm etric. \n\nMetadata: {'id': 2}\n\n----------------------------------------------------------------------------------------------------\n\nDocument 8:\n\n\n\nM. Rahman and Y. Watanobe, “Chatgpt for Education and research: Opportunities, threats, and strategies,” 2023, doi: 10.20944/preprints202303.0473.v1. [16] N. Oh, G.-S. Choi, and W.\n\nMetadata: {'id': 7}\n\n----------------------------------------------------------------------------------------------------\n\nDocument 9:\n\n\n\n+ M ore res is tant to the inf luenc e of outl iers . - Identifying the out lier too aggres s ive. - Taking a long ti me to run and compu te r intens ive.\n\nMetadata: {'id': 1}\n\n----------------------------------------------------------------------------------------------------\n\nDocument 10:\n\n\n\n4, p. 410, Apr. 2023, doi: https://doi.org/10.3390/educsci13040410. [23]  D. Drain, C. I. Clement, G. Serrato, and N. Sundaresan, “DeepDebug: Fixing Python Bugs Using Stack Traces, Backtranslation, and Code Skeletons,” arXiv (Cornell University), May 2021, doi: https://doi.org/10.48550/arxiv.2105.09352. [24] N. Nguyen and S. Nadi, “An empirical evaluation of GitHub copilot’s code suggestions,” Proceedings of the 19th International Conference on Mining Software Repositories, May 2022, doi: https://doi.org/10.1145/3524842.3528470. \n\nMetadata: {'id': 12}\n\n----------------------------------------------------------------------------------------------------\n\nDocument 11:\n\n\n\nK. Lo, “What Is the Impact of ChatGPT on Education? A Rapid Review of the Literature,” Education Sciences, vol. 13, no.\n\nMetadata: {'id': 11}\n\n----------------------------------------------------------------------------------------------------\n\nDocument 12:\n\n\n\n(2023). Use chat GPT to solve programming bugs. In Proceedings of the 12th International Conference on Computer and Automation Engineering (ICCAE '23), doi: 10.55529/ijitc.31.17.22. [5] Sobania, N., Moser, T., & Fraser, G. (2023). An analysis of the automatic bug fixing performance of ChatGPT. In Proceedings of the 2023 ACM SIGPLAN International Conference on Systems, Programming, Languages, and Applications (SPLASH '23), doi: 10.48550/arXiv.2301.08653. [6] Derrick Lin, James Koppel, Angela Chen, Armando Solar-Lezama. \"QuixBugs: A Multi-Lingual Program Repair Benchmark Set Based on the Quixey Challenge.\" Proceedings of the 38th International Conference on Software Engineering, 2017, pp. 60-63, doi: g/10.1145/3505247. [7] He Ye, Matias Martinez, Thomas Durieux, Martin Monperrus. \"A comprehensive study of automatic program repair on the QuixBugs benchmark.\" Empirical Software Engineering, vol. 26, no. 3, 2021, pp. 1-47, doi: 10.1016/j.jss.2019.01.069. [8] Fan, Z., Gao, X., Mirchev, M., Roychoudhury, A., & Tan, S. H. (2023). Automated repair of programs from large language models. In Proceedings of the 2023 ACM SIGPLAN International Conference on Systems, Programming, Languages, and Applications (SPLASH '23), doi: 10.48550/arXiv.2205.10583. [9] Z. Feng, D. Guo, D. Tang, N. Duan, X. Feng, M. Gong, L. Shou, B. Qin, T. Liu, D. Jiang et al., “CodeBERT: A pre-trained model for programming and natural languages,” in Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: Findings, 2020, pp. 1536–1547, doi: 10.18653/v1/2020.findings-emnlp.139 [10] C. Clement, D. Drain, J. Timcheck, A. Svyatkovskiy, and N. Sundaresan, “PyMT5: Multi-mode translation of natural language and Python code with transformers,” in Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), 2020, pp. 9052– 9065. [11] J. A. Prenner, H. Babii, and R. Robbes, “Can openai's codex fix bugs?,” Proceedings of the Third International Workshop on Automated Program Repair, 2022, doi: 10.1145/3524459.3527351. [12] H. Ye, M. Martinez, T. Durieux, and M. Monperrus, “A comprehensive study of automatic program repair on the QuixBugs benchmark,” 2019 IEEE 1st International Workshop on Intelligent Bug Fixing (IBF), 2019, doi: 10.1016/j.jss.2020.110825. [13] Tian, Haoye, dkk. Is ChatGPT the Ultimate Programming Assistant -- How far is it? 2023.\n\nMetadata: {'id': 5}\n\n----------------------------------------------------------------------------------------------------\n\nDocument 13:\n\n\n\nY. Lee, “Chatgpt goes to operating room: Evaluating GPT-4 performance and its potential in surgical education and training in the era of large language models,” 2023, doi: 10.1101/2023.03.16.23287340. [17] H.\n\nMetadata: {'id': 8}\n"}]},{"cell_type":"code","source":"import cohere\n\n# Initialize Together.ai client\nco = cohere.Client(\n    base_url=\"https://api.together.xyz/v1\",\n)\n\ndef rerank_documents(query, retrieved_docs):\n    \"\"\"\n    Rerank documents using Together.ai based on the query.\n    \"\"\"\n    # Prepare the document texts from the retrieved documents\n    doc_texts = [doc['content'] for doc in retrieved_docs]\n\n    # Call Together.ai reranking model\n    response = co.rerank(\n        model=\"Salesforce/Llama-Rank-V1\",  # Reranking model\n        query=query,\n        documents=doc_texts,\n        top_n=len(doc_texts)  # Return all documents but reranked\n    )\n\n    # Extract the reranked document texts\n    reranked_docs = [retrieved_docs[i] for i in [doc['index'] for doc in response['results']]]\n    return reranked_docs\n\n# Update your RAG chain to include reranking after retrieval\nrewrite_retrieve_read_chain = (\n    {\n        \"context\": {\"x\": RunnablePassthrough()} \n                   | rewrite_prompt\n                   | llm\n                   | StrOutputParser()\n                   | retriever\n                   | (lambda docs, inputs: rerank_documents(inputs['question'], docs)),  # Add reranking step\n        \"question\": RunnablePassthrough()\n    }\n    | prompt\n    | llm\n    | StrOutputParser()\n)\n","metadata":{},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"input_query = \"QuixBug is a benchmark for automatic program repair! Why Gaussian Assumption is important?\"\noutput = rewrite_retrieve_read_chain.invoke(input_query)\n\nprint(output)","metadata":{},"execution_count":54,"outputs":[{"ename":"TypeError","evalue":"<lambda>() missing 1 required positional argument: 'inputs'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Input \u001b[0;32mIn [54]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m input_query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQuixBug is a benchmark for automatic program repair! Why Gaussian Assumption is important?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mrewrite_retrieve_read_chain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_query\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(output)\n","File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/langchain_core/runnables/base.py:2876\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   2874\u001b[0m context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, config)\n\u001b[1;32m   2875\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2876\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2877\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2878\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config)\n","File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/langchain_core/runnables/base.py:3579\u001b[0m, in \u001b[0;36mRunnableParallel.invoke\u001b[0;34m(self, input, config)\u001b[0m\n\u001b[1;32m   3574\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m get_executor_for_config(config) \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[1;32m   3575\u001b[0m         futures \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   3576\u001b[0m             executor\u001b[38;5;241m.\u001b[39msubmit(_invoke_step, step, \u001b[38;5;28minput\u001b[39m, config, key)\n\u001b[1;32m   3577\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m key, step \u001b[38;5;129;01min\u001b[39;00m steps\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m   3578\u001b[0m         ]\n\u001b[0;32m-> 3579\u001b[0m         output \u001b[38;5;241m=\u001b[39m {key: future\u001b[38;5;241m.\u001b[39mresult() \u001b[38;5;28;01mfor\u001b[39;00m key, future \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(steps, futures)}\n\u001b[1;32m   3580\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[1;32m   3581\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n","File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/langchain_core/runnables/base.py:3579\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   3574\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m get_executor_for_config(config) \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[1;32m   3575\u001b[0m         futures \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   3576\u001b[0m             executor\u001b[38;5;241m.\u001b[39msubmit(_invoke_step, step, \u001b[38;5;28minput\u001b[39m, config, key)\n\u001b[1;32m   3577\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m key, step \u001b[38;5;129;01min\u001b[39;00m steps\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m   3578\u001b[0m         ]\n\u001b[0;32m-> 3579\u001b[0m         output \u001b[38;5;241m=\u001b[39m {key: \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m key, future \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(steps, futures)}\n\u001b[1;32m   3580\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[1;32m   3581\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n","File \u001b[0;32m~/opt/anaconda3/lib/python3.9/concurrent/futures/_base.py:446\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    444\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    445\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 446\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    447\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    448\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m()\n","File \u001b[0;32m~/opt/anaconda3/lib/python3.9/concurrent/futures/_base.py:391\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    389\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m    390\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 391\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    392\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    393\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    394\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m~/opt/anaconda3/lib/python3.9/concurrent/futures/thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture\u001b[38;5;241m.\u001b[39mset_exception(exc)\n","File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/langchain_core/runnables/base.py:3563\u001b[0m, in \u001b[0;36mRunnableParallel.invoke.<locals>._invoke_step\u001b[0;34m(step, input, config, key)\u001b[0m\n\u001b[1;32m   3561\u001b[0m context \u001b[38;5;241m=\u001b[39m copy_context()\n\u001b[1;32m   3562\u001b[0m context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, child_config)\n\u001b[0;32m-> 3563\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3564\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3565\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3566\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchild_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3567\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/langchain_core/runnables/base.py:2878\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   2876\u001b[0m             \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   2877\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2878\u001b[0m             \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2879\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[1;32m   2880\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n","File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/langchain_core/runnables/base.py:4474\u001b[0m, in \u001b[0;36mRunnableLambda.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   4460\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Invoke this Runnable synchronously.\u001b[39;00m\n\u001b[1;32m   4461\u001b[0m \n\u001b[1;32m   4462\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4471\u001b[0m \u001b[38;5;124;03m    TypeError: If the Runnable is a coroutine function.\u001b[39;00m\n\u001b[1;32m   4472\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4473\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunc\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 4474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_with_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4475\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_invoke\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4476\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4477\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4478\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4479\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4480\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   4481\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m   4482\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot invoke a coroutine function synchronously.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4483\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUse `ainvoke` instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4484\u001b[0m     )\n","File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/langchain_core/runnables/base.py:1785\u001b[0m, in \u001b[0;36mRunnable._call_with_config\u001b[0;34m(self, func, input, config, run_type, **kwargs)\u001b[0m\n\u001b[1;32m   1781\u001b[0m     context \u001b[38;5;241m=\u001b[39m copy_context()\n\u001b[1;32m   1782\u001b[0m     context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, child_config)\n\u001b[1;32m   1783\u001b[0m     output \u001b[38;5;241m=\u001b[39m cast(\n\u001b[1;32m   1784\u001b[0m         Output,\n\u001b[0;32m-> 1785\u001b[0m         \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1786\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcall_func_with_variable_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1787\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1788\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1789\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1790\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1791\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1792\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m   1793\u001b[0m     )\n\u001b[1;32m   1794\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1795\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n","File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/langchain_core/runnables/config.py:398\u001b[0m, in \u001b[0;36mcall_func_with_variable_args\u001b[0;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[1;32m    397\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m run_manager\n\u001b[0;32m--> 398\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/langchain_core/runnables/base.py:4330\u001b[0m, in \u001b[0;36mRunnableLambda._invoke\u001b[0;34m(self, input, run_manager, config, **kwargs)\u001b[0m\n\u001b[1;32m   4328\u001b[0m                 output \u001b[38;5;241m=\u001b[39m chunk\n\u001b[1;32m   4329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 4330\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mcall_func_with_variable_args\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4331\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m   4332\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4333\u001b[0m \u001b[38;5;66;03m# If the output is a Runnable, invoke it\u001b[39;00m\n\u001b[1;32m   4334\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, Runnable):\n","File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/langchain_core/runnables/config.py:398\u001b[0m, in \u001b[0;36mcall_func_with_variable_args\u001b[0;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[1;32m    397\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m run_manager\n\u001b[0;32m--> 398\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mTypeError\u001b[0m: <lambda>() missing 1 required positional argument: 'inputs'"]}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}